{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training set\n",
    "df = pd.read_csv('inclassfakejobs/train.csv')\n",
    "# Split string data\n",
    "df_tr = df[['title', 'company_profile', 'description',\n",
    "                'requirements', 'benefits', 'fraudulent']]\n",
    "df_tr = df_tr.fillna('')\n",
    "\n",
    "# Import test set\n",
    "df = pd.read_csv('inclassfakejobs/test.csv')\n",
    "df_t = df[['title', 'company_profile', 'description',\n",
    "                'requirements', 'benefits']]\n",
    "df_t = df_t.fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Frequency Tokenization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenFreq(backbone_train, backbone_test, col):\n",
    "    vectorizer = CountVectorizer(stop_words='english', max_features=2000)\n",
    "\n",
    "    corpus_train = backbone_train[f'{col}']\n",
    "    corpus_test = backbone_test[f'{col}']\n",
    "\n",
    "    cv = vectorizer.fit(corpus_train)\n",
    "    X_train = vectorizer.transform(corpus_train)\n",
    "    X_test = vectorizer.transform(corpus_test)\n",
    "\n",
    "\n",
    "    freq_train = X_train.toarray().T\n",
    "    freq_test = X_test.toarray().T\n",
    "    dims = X_train.toarray().T.shape\n",
    "\n",
    "    vocab = cv.vocabulary_\n",
    "    vocab_keys = list(vocab.keys())\n",
    "\n",
    "    for i in range(dims[0]):\n",
    "        backbone_train[f'{col}_{vocab_keys[i]}'] = freq_train[i]\n",
    "        backbone_test[f'{col}_{vocab_keys[i]}'] = freq_test[i]\n",
    "    return backbone_train, backbone_test, vocab_keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pl3os\\AppData\\Local\\Temp/ipykernel_15096/1317980121.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  backbone_train[f'{col}_{vocab_keys[i]}'] = freq_train[i]\n",
      "C:\\Users\\pl3os\\AppData\\Local\\Temp/ipykernel_15096/1317980121.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  backbone_test[f'{col}_{vocab_keys[i]}'] = freq_test[i]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'company_profile', 'description', 'requirements', 'benefits'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_dict = dict([])\n",
    "for col in ['title', 'company_profile', 'description', 'requirements', 'benefits']:\n",
    "    df_tr, df_t, col_vocab = tokenFreq(backbone_train=df_tr, backbone_test=df_t, col=col)\n",
    "    vocab_dict[col] = col_vocab\n",
    "\n",
    "df_train = df_tr.drop(['title', 'company_profile', 'description', 'requirements', 'benefits', 'fraudulent'], axis = 1)\n",
    "df_test = df_t.drop(['title', 'company_profile', 'description', 'requirements', 'benefits'], axis = 1)\n",
    "vocab_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('peter_train7.csv')\n",
    "df_test.to_csv('peter_test7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295     3\n",
       "361     2\n",
       "465     2\n",
       "1196    2\n",
       "1419    2\n",
       "1651    3\n",
       "1688    2\n",
       "1936    2\n",
       "2140    3\n",
       "2329    2\n",
       "2802    2\n",
       "4533    2\n",
       "5478    2\n",
       "5633    2\n",
       "7658    2\n",
       "9082    2\n",
       "Name: description_company, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.description_company[df_train['description_company']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10728, 10000), (7152, 10000))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10728, 10006), (10728, 10006))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_t.shape, df_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
